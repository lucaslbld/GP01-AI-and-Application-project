# TrustThePixels: Machine Learning Techniques for Distinguishing AI-Generated Images from Real Photographs

**Members**  
- Thibault MICHEL, Computer science, Hanyang University, thibault.michel@edu.devinci.fr  
- Arthur LOURENÇO, Computer science, Hanyang University, arthur.lourenco@edu.ece.fr
- Jean LECORNET, Computer science, Hanyang University, jean.lecornet@edu.ece.fr
- Loup FLORENTIN, Computer science, Hanyang University, loup.florentin@edu.ece.fr
- Lucas LEBLOND, Computer science, Hanyang University, lucas.leblond@edu.ece.fr

---

## Table of Contents

1. [Introduction](#Introduction)  
2. [Datasets](#datasets)  
3. [Methodology](#methodology)  
4. [Evaluation & Analysis](#evaluation--analysis)  
5. [Related Work](#related-work)  
6. [Conclusion](#conclusion)  
7. [Video / Audio Link](#video--audio-link)

---

## Introduction

### Motivation
In recent years, the rapid development of generative AI systems such as ChatGPT, Midjourney, DALL·E, and more recently Sora has completely transformed the way digital content is created and shared. Access to these technologies has become extremely easy for the general public. While this accessibility brings many positive opportunities, it also raises serious concerns, especially regarding misinformation, content authenticity, and the spread of manipulated media.

Generative models have become so advanced that it is increasingly difficult for humans to distinguish AI-generated images from real photographs. On social networks, misleading or entirely fabricated content can circulate faster than verified information, amplifying the risk of confusion and intentional deception. As a result, it is now more important than ever to develop automated tools capable of identifying whether an image is real or produced by AI.

Such detection systems could eventually be integrated into social media platforms to automatically verify uploaded content and require AI-generated images to be clearly labeled. This would contribute to transparency, trust, and safer digital ecosystems.

### Project Goal
The objective of this project is to develop a machine learning model capable of determining whether an image is a real photograph or generated by artificial intelligence. To achieve this, we will build a complete end-to-end pipeline: collecting and describing the dataset, preprocessing and preparing the images, extracting relevant features, training classification models, and evaluating their performance. The aim is to explore how machine learning can support digital authenticity and contribute to future systems that automatically detect AI-generated visual content.

## Datasets
During the early stages of the project, we examined several datasets containing AI-generated images and real photographs. However, most available datasets presented two main problems.

First, many of them were extremely large, often containing hundreds of thousands of images. While these datasets are excellent for large-scale research, they are impractical for a student project because they require long download times, significant storage space, and substantial computing resources for both preprocessing and training.

Second, the smaller datasets we found were not suitable for our objectives. Many lacked diversity, included too few samples, or were limited to specific image categories such as human faces. Others suffered from poor labeling quality or contained images that did not align with the types of modern AI-generated content we wanted to study. Additionally, several datasets contained images with highly inconsistent resolutions, including extremely small files such as 32×32 or 64×64 pixels, which significantly increases noise during training and reduces the model’s ability to generalize.

Due to these limitations, we ultimately decided to use a large and diverse dataset from Hugging Face:
https://huggingface.co/datasets/theminji/ai-vs-real-200k

This dataset originally contains roughly 200,000 images divided into two categories: AI-generated content and real photographs. It covers a broad range of visual styles and subjects, making it highly relevant to our goal of detecting modern generative AI content.

However, using the full dataset was unnecessary for our project. To build a manageable and balanced working set, we wrote a Python script that loads the dataset, identifies the AI and Real labels automatically, randomly selects 5,000 AI-generated images and 5,000 real images, converts all images to RGB format for consistency, and saves them into two dedicated folders. The final result is a curated dataset of 10,000 images, perfectly balanced and much easier to work with for training and evaluation.

Below is the code used to create this reduced dataset.

    import os
    import random
    from datasets import load_dataset

    def main():
        ds = load_dataset("theminji/ai-vs-real-200k")
        train = ds["train"]

    print(train)
    print("Features:", train.features)

    label_field = "label"

    label_names = train.features[label_field].names
    print("Label names:", label_names)

  
    ai_label = None
    real_label = None

    for idx, name in enumerate(label_names):
        lname = name.lower()
        if "ai" in lname or "fake" in lname or "generated" in lname:
            ai_label = idx
        if "real" in lname:
            real_label = idx

    print("AI label:", ai_label, "(", label_names[ai_label], ")")
    print("Real label:", real_label, "(", label_names[real_label], ")")

    ai_indices = []
    real_indices = []

    for idx in range(len(train)):
        lbl = train[idx][label_field]
        if lbl == ai_label:
            ai_indices.append(idx)
        elif lbl == real_label:
            real_indices.append(idx)

    print("Total AI images:", len(ai_indices))
    print("Total Real images:", len(real_indices))

    random.seed(42)
    ai_sample = random.sample(ai_indices, 5000)
    real_sample = random.sample(real_indices, 5000)

    os.makedirs("dataset/AI", exist_ok=True)
    os.makedirs("dataset/Real", exist_ok=True)

    for i, idx in enumerate(ai_sample):
        img = train[idx]["image"]
        if img.mode != "RGB":
            img = img.convert("RGB")
        img.save(f"dataset/AI/ai_{i:04d}.jpg")

    for i, idx in enumerate(real_sample):
        img = train[idx]["image"]
        if img.mode != "RGB":
            img = img.convert("RGB")
        img.save(f"dataset/Real/real_{i:04d}.jpg")


    if __name__ == "__main__":
    main()


### Download the Dataset

Our dataset (10000 images)
[Click here to download the dataset](https://github.com/lucaslbld/GP01-AI-and-Application-project/releases/download/v1.0/dataset.zip)


## Methodology

The goal of this project is to train a machine learning model that can look at an image and decide whether it was created by a generative AI model or captured in the real world. To build such a system, we followed a step-by-step workflow that transforms raw data into a trained model capable of making reliable predictions.

The first step was to prepare a clean and balanced dataset. The original dataset contained around 200,000 images, which is too large to use directly in our project. To keep the project manageable while still preserving a good level of diversity, we wrote a Python script that randomly selects 5,000 AI-generated images and 5,000 real images from the full dataset. All selected images are converted to RGB format and saved into two folders named AI and Real. This gives us a balanced subset of 10,000 images that is much easier to work with during training and evaluation.

Once the dataset was ready, we applied image preprocessing. Machine learning models cannot work directly with raw pictures, so each image is transformed in a consistent way. Every image is resized to 224x224 pixels, converted into a tensor and normalized using standard ImageNet statistics. This ensures that all images have a similar structure from the model’s point of view, even if they originally came from different sources.

After preparing the images, we chose the model we wanted to train. Instead of building a neural network from scratch, which would require a much larger dataset, we used a pre-trained model called ResNet34. This model has already been trained on millions of images and is able to recognize general visual features such as edges, shapes and textures. We only needed to fine-tune it for our specific task, which means keeping the learned visual features but replacing the final layer so that the model outputs two classes: AI and Real. This approach is efficient and fast to train. We used libraries such as PyTorch, the timm model collection and PyTorch Lightning to simplify the training loop and model management.

The training process is done in several passes through the dataset, which are called epochs. During each epoch, the model makes predictions, compares them with the correct labels, and adjusts its internal parameters to reduce errors. Over time, the model becomes better at recognizing patterns typically found in AI-generated images or real photographs. We also kept a separate part of the dataset as a validation set to check how well the model performs on images it has never seen before.

After training, we saved the final model and created two prediction scripts. The first script performs a standard prediction by selecting three random images from the dataset and displaying the model’s predictions along with confidence scores. This helps verify that the model behaves correctly on known data. The second script allows the user to choose any custom image and tests the model on it. This makes it possible to check how the model reacts to real-world examples, such as images downloaded from the internet or taken manually. Both scripts apply the same preprocessing steps as during training and use the trained model to output a prediction and probabilities.

This methodology gives us a complete and reproducible workflow for training and evaluating an AI versus Real image classifier. It also highlights the practical challenges of this task, such as dealing with different types of images, variations in visual styles, and the continually increasing realism of modern AI-generated content.

## Evaluation & Analysis

To evaluate the performance of our model, we tested it on two different types of images: samples taken directly from our dataset, and images collected manually from external sources such as the internet. This allows us to understand both how well the model learned the training distribution and how well it generalizes to real-world situations.

When we tested the model on random images taken from the prepared dataset, the results were consistently correct. The model correctly classified AI images as AI and real images as real with very high confidence scores. These results show that the model learned to recognize the patterns present in the dataset, such as textures, colors, lighting styles or compression characteristics that may be typical of AI-generated content or real photographs. These internal tests confirm that the training process, the preprocessing steps and the model architecture were all functioning as expected.

<img width="1483" height="618" alt="ScreenEvalpredict" src="https://github.com/user-attachments/assets/3c86dad5-234d-43d6-bfd0-9a2f4e17c8cb" />

However, the results were noticeably different when testing the second prediction script on external images selected by the user. For these images, the model often made incorrect predictions. Some highly realistic AI portraits were classified as real, while simple real images such as a dog photograph or a cityscape were sometimes classified as AI. Even a well-known real picture of Will Smith was predicted as AI with high confidence. These examples illustrate a clear limitation in the generalization ability of the model.

<img width="777" height="588" alt="ScreenEvalpredictperso1" src="https://github.com/user-attachments/assets/d2fc2777-f400-4f15-9ceb-3a7aac445a46" />

<img width="721" height="555" alt="ScreenEvalpredictperso2" src="https://github.com/user-attachments/assets/0f0ee9a3-6ab4-49aa-a350-54fc8e99e3c5" />

This difference can be explained by the fact that the model was trained exclusively on images coming from one dataset. Even though the dataset is large and diverse, it still has its own visual style, distribution and characteristics. The model learns the statistical patterns of this dataset, but images from the internet can have different properties such as higher resolution, different compression methods, different lighting styles, more modern camera sensors, or more recent AI generators that the model has never seen before. As a result, the model performs well inside the training distribution but struggles when the images come from a different source or follow a different visual pattern.

Looking at the confidence scores also helps to understand the model’s behavior. When predicting on images from the dataset, the model outputs probabilities close to 1.00 for the correct class. But on external images, the model can still output very high confidence for an incorrect class. This means that the model is not simply unsure, but that it is genuinely misled by features that resemble the patterns it learned during training. This is a common issue in machine learning known as the generalization gap.

The images above illustrate this phenomenon. The first example comes from the dataset and is classified perfectly. The next examples are user-selected images where the model often makes wrong predictions despite appearing confident. These results highlight the importance of dataset diversity and show that real-world image classification tasks require much broader training data or more advanced techniques.

In summary, the model performs very well on the dataset it was trained on but shows limited generalization to external images. This evaluation helps us understand the strengths and weaknesses of our approach and demonstrates that even with a powerful model like ResNet34, reliable detection of AI-generated images in the real world remains a challenging task.

## Related Work


## Conclusion

## Video / Audio Link

