# TrustThePixels: Machine Learning Techniques for Distinguishing AI-Generated Images from Real Photographs

**Members**  
- Thibault MICHEL, Computer science, Hanyang University, thibault.michel@edu.devinci.fr  
- Arthur LOURENÇO, Computer science, Hanyang University, arthur.lourenco@edu.ece.fr
- Jean LECORNET, Computer science, Hanyang University, jean.lecornet@edu.ece.fr
- Loup FLORENTIN, Computer science, Hanyang University, loup.florentin@edu.ece.fr
- Lucas LEBLOND, Computer science, Hanyang University, lucas.leblond@edu.ece.fr

---

## Table of Contents

1. [Introduction](#Introduction)  
2. [Datasets](#datasets)  
3. [Methodology](#methodology)  
4. [Evaluation & Analysis](#evaluation--analysis)  
5. [Related Work](#related-work)  
6. [Conclusion](#conclusion)  
7. [Video / Audio Link](#video--audio-link)

---

## Introduction

### Motivation
In recent years, the rapid development of generative AI systems such as ChatGPT, Midjourney, DALL·E, and more recently Sora has completely transformed the way digital content is created and shared. Access to these technologies has become extremely easy for the general public. While this accessibility brings many positive opportunities, it also raises serious concerns, especially regarding misinformation, content authenticity, and the spread of manipulated media.

Generative models have become so advanced that it is increasingly difficult for humans to distinguish AI-generated images from real photographs. On social networks, misleading or entirely fabricated content can circulate faster than verified information, amplifying the risk of confusion and intentional deception. As a result, it is now more important than ever to develop automated tools capable of identifying whether an image is real or produced by AI.

Such detection systems could eventually be integrated into social media platforms to automatically verify uploaded content and require AI-generated images to be clearly labeled. This would contribute to transparency, trust, and safer digital ecosystems.

### Project Goal
The objective of this project is to develop a machine learning model capable of determining whether an image is a real photograph or generated by artificial intelligence. To achieve this, we will build a complete end-to-end pipeline: collecting and describing the dataset, preprocessing and preparing the images, extracting relevant features, training classification models, and evaluating their performance. The aim is to explore how machine learning can support digital authenticity and contribute to future systems that automatically detect AI-generated visual content.

## Datasets
During the early stages of the project, we examined several datasets containing AI-generated images and real photographs. However, most available datasets presented two main problems.

First, many of them were extremely large, often containing hundreds of thousands of images. While these datasets are excellent for large-scale research, they are impractical for a student project because they require long download times, significant storage space, and substantial computing resources for both preprocessing and training.

Second, the smaller datasets we found were not suitable for our objectives. Many lacked diversity, included too few samples, or were limited to specific image categories such as human faces. Others suffered from poor labeling quality or contained images that did not align with the types of modern AI-generated content we wanted to study. Additionally, several datasets contained images with highly inconsistent resolutions, including extremely small files such as 32×32 or 64×64 pixels, which significantly increases noise during training and reduces the model’s ability to generalize.

Due to these limitations, we ultimately decided to use a large and diverse dataset from Hugging Face:
https://huggingface.co/datasets/theminji/ai-vs-real-200k

This dataset originally contains roughly 200,000 images divided into two categories: AI-generated content and real photographs. It covers a broad range of visual styles and subjects, making it highly relevant to our goal of detecting modern generative AI content.

However, using the full dataset was unnecessary for our project. To build a manageable and balanced working set, we wrote a Python script that loads the dataset, identifies the AI and Real labels automatically, randomly selects 5,000 AI-generated images and 5,000 real images, converts all images to RGB format for consistency, and saves them into two dedicated folders. The final result is a curated dataset of 10,000 images, perfectly balanced and much easier to work with for training and evaluation.

Below is the code used to create this reduced dataset.

    import os
    import random
    from datasets import load_dataset

    def main():
        ds = load_dataset("theminji/ai-vs-real-200k")
        train = ds["train"]

    print(train)
    print("Features:", train.features)

    label_field = "label"

    label_names = train.features[label_field].names
    print("Label names:", label_names)

  
    ai_label = None
    real_label = None

    for idx, name in enumerate(label_names):
        lname = name.lower()
        if "ai" in lname or "fake" in lname or "generated" in lname:
            ai_label = idx
        if "real" in lname:
            real_label = idx

    print("AI label:", ai_label, "(", label_names[ai_label], ")")
    print("Real label:", real_label, "(", label_names[real_label], ")")

    ai_indices = []
    real_indices = []

    for idx in range(len(train)):
        lbl = train[idx][label_field]
        if lbl == ai_label:
            ai_indices.append(idx)
        elif lbl == real_label:
            real_indices.append(idx)

    print("Total AI images:", len(ai_indices))
    print("Total Real images:", len(real_indices))

    random.seed(42)
    ai_sample = random.sample(ai_indices, 5000)
    real_sample = random.sample(real_indices, 5000)

    os.makedirs("dataset/AI", exist_ok=True)
    os.makedirs("dataset/Real", exist_ok=True)

    for i, idx in enumerate(ai_sample):
        img = train[idx]["image"]
        if img.mode != "RGB":
            img = img.convert("RGB")
        img.save(f"dataset/AI/ai_{i:04d}.jpg")

    for i, idx in enumerate(real_sample):
        img = train[idx]["image"]
        if img.mode != "RGB":
            img = img.convert("RGB")
        img.save(f"dataset/Real/real_{i:04d}.jpg")


    if __name__ == "__main__":
    main()


### Download the Dataset

Our dataset (10000 images)
[Click here to download the dataset](https://github.com/lucaslbld/GP01-AI-and-Application-project/releases/download/v1.0/dataset.zip)


## Methodology


## Evaluation & Analysis

## Related Work


## Conclusion

## Video / Audio Link

